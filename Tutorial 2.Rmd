---
title: "Tutorial1 Ch3"
author: "Ryan Huang"
date: "7/26/2019"
output:
  html_document:
    df_print: paged
    toc: true
    toc_depth: 4
    number_sections: true
    toc_float: true
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(rethinking)
library(rstan)
library(gridExtra)
```

## Chapter 3

In this chapter, we will learn about the basic skills for working with samples from the posterior distribution.

In last chapter, we use grid approximation and MCMC(stan) to get the posterior distribution. The model's work has done but our work just started. We are usually required to answer the following questions:

* Interval Estimation
  + How much posterior probability lies below some parameter value?
  + How much posterior probability lies between two parameter values?
  + Which parameter value marks the lower 5% of the posterior probability?
  + Which range of parameter values contains 90% of the posterior probability?

* Point Estimation
Which parameter value has highest posterior probability?

In our past statistics class, these questions are answered with the help of some formulas.
For example, we have formulas to calculate CI for a regression problem:
![Confidence Interval](tutorial2.1.png)
However, in this class, we use another approach. Since the model give us the samples from the whole posterior distribution, we can make inference from it.

### Samples vs Posterior distribution
What is a posterior distribution?

"The posterior defines the expected frequency that different parameter values will appear."


The posterior distribution from the grid approximation shows the expected probability of each possible `p` values (the proportion of water on the Earch).
![Posterior Distribution](tutorial2.2.png)

In this simple example, the grid approximation generates the whole posterior distribution, while Stan gives us samples from the posterior. However, in most cases we can't have the posterior distribution but only samples.

So in this chapter weâ€™ll begin to use samples to summarize and simulate model output.

### Grid: Sampling from posterior
Grid approximation provides us with the exact posterior distribution. However, we want to make inference using the samples. So we have to draw samples from the posterior first.
```{r}
# posterior from grid (ch2)
d =
   tibble(
     p_grid = seq(from = 0, to = 1, length.out = 100),  # define grid
     prior  = 1) %>%                                   # define prior
   # compute likelihood at each value in grid
   mutate(
     grid.likelihood = dbinom(6, size = 9, prob = p_grid)) %>%  
   # compute product of likelihood and prior
   mutate(
     grid.unstd_post = grid.likelihood * prior) %>%
   # standardize the posterior, so it sums to 1
   mutate(
     grid.post  = grid.unstd_post / sum(grid.unstd_post))
```
Draw samples from posterior distribution
```{r}
sample.size = 1e4 # 10,000 samples

grid.samples = tibble(
  samples = sample(d$p_grid,
                   size = sample.size,
                   prob = d$grid.post,
                   replace = T),
  sample_number = 1:sample.size)

plt2.1 = grid.samples %>% 
  ggplot() +
  geom_point(aes(sample_number, samples), alpha=0.5) +
  labs(y="proportion water (p)")

plt2.2 = grid.samples %>% 
  ggplot() +
  geom_density(aes(samples)) +
  labs(x="proportion water (p)")

grid.arrange(plt2.1, plt2.2, nrow=1)
```
### MCMC
```{r}
binom.model = "
data {
	int N; // number of data
	int W; // number of w observations
}
parameters {
	real<lower=0, upper=1> p;
}
model {
	p ~ uniform(0,1);
	W ~ binomial(N, p);
}
"
binom.data = list(N = 9, W = 6)
binom.fit = stan(model_code = binom.model, 
                 data = binom.data, 
                 chains = 2,
                 iter = sample.size)

mcmc.samples = 
  as.data.frame(binom.fit) %>% 
  mutate(sample_number = 1:sample.size) %>% 
  rename(., "samples" = "p") # forgive the weird r logic...

plt2.3 = mcmc.samples %>% 
  ggplot() +
  geom_point(aes(sample_number, samples), alpha=0.5) +
  labs(y="proportion water (p)")

plt2.4 = mcmc.samples %>% 
  ggplot() +
  geom_density(aes(samples)) +
  labs(x="proportion water (p)")

grid.arrange(plt2.3, plt2.4, nrow=1)
```

